{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_UR-jKQ8jRbZ"
      },
      "outputs": [],
      "source": [
        "%matplotlib inline\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import regex as re"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "n9QmuMEyj2ok"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install vaderSentiment\n",
        "from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer"
      ],
      "metadata": {
        "id": "WAPcczEukGwz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "analyzer = SentimentIntensityAnalyzer()"
      ],
      "metadata": {
        "id": "CTo_CZG-kzDg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def untokenize(words):\n",
        "    \"\"\"\n",
        "    Untokenizing a text undoes the tokenizing operation, restoring\n",
        "    punctuation and spaces to the places that people expect them to be.\n",
        "    Ideally, `untokenize(tokenize(text))` should be identical to `text`,\n",
        "    except for line breaks.\n",
        "    \"\"\"\n",
        "    text = ' '.join(words)\n",
        "    step1 = text.replace(\"`` \", '\"').replace(\" ''\", '\"').replace('. . .',  '...')\n",
        "    step2 = step1.replace(\" ( \", \" (\").replace(\" ) \", \") \")\n",
        "    step3 = re.sub(r' ([.,:;?!%]+)([ \\'\"`])', r\"\\1\\2\", step2)\n",
        "    step4 = re.sub(r' ([.,:;?!%]+)$', r\"\\1\", step3)\n",
        "    step5 = step4.replace(\" '\", \"'\").replace(\" n't\", \"n't\").replace(\n",
        "         \"can not\", \"cannot\")\n",
        "    step6 = step5.replace(\" ` \", \" '\")\n",
        "    step7 = step6.replace(\"rt\", \"\")\n",
        "    return step7.strip()"
      ],
      "metadata": {
        "id": "4AEZAllNsAir"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def sentiment_analyze(sent_token):\n",
        "\n",
        "    sentence = untokenize(sent_token)\n",
        "\n",
        "    sentiment_dict = analyzer.polarity_scores(sentence)\n",
        "\n",
        "    if sentiment_dict['compound'] > 0.0 :\n",
        "        return 1\n",
        " \n",
        "    elif sentiment_dict['compound'] < -0.0 :\n",
        "        return -1\n",
        "\n",
        "    else :\n",
        "      return 0"
      ],
      "metadata": {
        "id": "1J7LIWA4rdAz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "from google.colab import files\n",
        "\n",
        "tweets = []\n",
        "labels = []\n",
        "\n",
        "for line in open('/content/drive/MyDrive/ML Project/Dataset/stocknet-dataset-master/tweet/preprocessed/AAPL/2014-01-01', 'r'):\n",
        "    tweet_dict = json.loads(line)\n",
        "    tweet_text = tweet_dict['text'] \n",
        "    tweets.append(tweet_text)\n",
        "    labels.append(sentiment_analyze(tweet_text))\n",
        "\n",
        "print(tweets)\n",
        "label_df = pd.DataFrame(list(labels), columns =['SENTIMENT'])\n",
        "label_df.to_csv('try.csv') \n",
        "files.download('try.csv')\n"
      ],
      "metadata": {
        "id": "2BN6DKKOnlGM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(labels)"
      ],
      "metadata": {
        "id": "gabH1-DpqS_r"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "comp = 'MSFT'"
      ],
      "metadata": {
        "id": "Ozfxa2Wu7eJC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "# Parent Directory path\n",
        "parent_dir = \"/content/drive/MyDrive/ML Project/Dataset/Sentiments/\"\n",
        "  \n",
        "# Path\n",
        "path = os.path.join(parent_dir, comp)\n",
        "\n",
        "os.mkdir(path)"
      ],
      "metadata": {
        "id": "pAEaQRZskgM2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def sentiment_file(file_path, date):\n",
        "\n",
        "  labels = []\n",
        "\n",
        "  for line in open(file_path, 'r'):\n",
        "    tweet_dict = json.loads(line)\n",
        "    tweet_text = tweet_dict['text'] \n",
        "    labels.append(sentiment_analyze(tweet_text))\n",
        "\n",
        "  pos = labels.count(1)\n",
        "  neut = labels.count(0)\n",
        "  neg = labels.count(-1)\n",
        "\n",
        "  return pos, neut, neg\n",
        "\n",
        "  # label_df = pd.DataFrame(list(labels), columns =['SENTIMENT'])\n",
        "  # label_df.to_csv('/content/drive/MyDrive/ML Project/Dataset/Sentiments/' + comp +'/'+date+'.csv')\n"
      ],
      "metadata": {
        "id": "D7g5078ouw-t"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "# Define the location of the directory\n",
        "path = r\"/content/drive/MyDrive/ML Project/Dataset/stocknet-dataset-master/tweet/preprocessed/\"+comp\n",
        "\n",
        "# Change the directory\n",
        "os.chdir(path)\n",
        "\n",
        "date = []\n",
        "positive = []\n",
        "neutral = []\n",
        "negative = []\n",
        "\n",
        "# Iterate over all the files in the directory\n",
        "for file in sorted(os.listdir()):\n",
        "      print(str(file))\n",
        "      file_path =f\"{path}/{file}\"\n",
        "      pos, neut, neg = sentiment_file(file_path, str(file))\n",
        "      date.append(str(file))\n",
        "      positive.append(pos)\n",
        "      neutral.append(neut)\n",
        "      negative.append(neg)\n",
        "\n",
        "a = np.sum(np.array(positive))\n",
        "b = np.sum(np.array(neutral))\n",
        "c = np.sum(np.array(negative))\n",
        "\n",
        "# stock_df = pd.DataFrame(\n",
        "#     {'DATE': date,\n",
        "#      'POSITIVE': positive,\n",
        "#      'NEUTRAL': neutral,\n",
        "#      'NEGATIVE' : negative\n",
        "#     })\n",
        "\n",
        "# label_df = pd.DataFrame(list(zip(labels), columns =['SENTIMENT'])\n",
        "#stock_df.to_csv('/content/drive/MyDrive/ML Project/Dataset/Sentiments/' + comp +'/'+'0000-00-00'+'.csv')\n"
      ],
      "metadata": {
        "id": "Q899-2rYsX7q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(a,b,c)"
      ],
      "metadata": {
        "id": "VQySN0e0Tu93"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import plotly.graph_objects as go\n",
        "\n",
        "labels = ['Positive','Neutral','Negative']\n",
        "values = [a,b,c]\n",
        "\n",
        "# Use `hole` to create a donut-like pie chart\n",
        "fig = go.Figure(data=[go.Pie(labels=labels, values=values, hole=.3)])\n",
        "fig.show()"
      ],
      "metadata": {
        "id": "78hpsVo1YYFt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# labels = [1,0,1]\n",
        "# date = \"2015-10-22\"\n",
        "# label_df = pd.DataFrame(list(labels), columns =['SENTIMENT'])\n",
        "# label_df.to_csv('/content/drive/MyDrive/ML Project/Dataset/Sentiments/AAPL/'+date+'.csv')"
      ],
      "metadata": {
        "id": "Kw6yscRZuPB-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "5WCQ4X3dwy2f"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}